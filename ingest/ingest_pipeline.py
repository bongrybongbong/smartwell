import os
from dotenv import load_dotenv

from document_loaders.utils import load_documents_from_folder
from langchain.text_splitter import RecursiveCharacterTextSplitter
from langchain_google_genai import GoogleGenerativeAIEmbeddings
from langchain_community.vectorstores import FAISS

# í™˜ê²½ë³€ìˆ˜ ë¶ˆëŸ¬ì˜¤ê¸°
load_dotenv()

# ë¬¸ì„œ í´ë” ê²½ë¡œ
input_dir = os.getenv("PDF_DIR", "docs")

# ì „ì²´ íŒŒì¼ ëª©ë¡ í™•ì¸
all_files = [f for f in os.listdir(input_dir) if os.path.isfile(os.path.join(input_dir, f))]
print(f"âœ… ì´ {len(all_files)}ê°œì˜ íŒŒì¼ì„ ê°ì§€í–ˆìŠµë‹ˆë‹¤.")

# 1. ë¬¸ì„œ ë¡œë”©
print("ğŸ“¥ ë¬¸ì„œ ë¡œë”© ì¤‘...")
docs = load_documents_from_folder(input_dir)
print(f"ğŸ” ì´ {len(docs)}ê°œì˜ í˜ì´ì§€ë¥¼ ë¡œë“œí–ˆìŠµë‹ˆë‹¤.")

# 2. í…ìŠ¤íŠ¸ ë¶„í• 
print("âœ‚ï¸ í…ìŠ¤íŠ¸ ë¶„í•  ì¤‘...")
splitter = RecursiveCharacterTextSplitter(chunk_size=1000, chunk_overlap=100)
split_docs = splitter.split_documents(docs)
print(f"ğŸ“„ ì´ {len(split_docs)}ê°œì˜ ì²­í¬ë¡œ ë¶„í• í–ˆìŠµë‹ˆë‹¤.")

# 3. ì„ë² ë”© ë° ë²¡í„° ì €ì¥
print("ğŸ”— ì„ë² ë”© ë° ë²¡í„° ì €ì¥ ì¤‘...")
embedding = GoogleGenerativeAIEmbeddings(model="models/embedding-001")
vectorstore = FAISS.from_documents(split_docs, embedding)
vectorstore.save_local("faiss_index")

print("âœ… FAISS ë²¡í„° ì €ì¥ ì™„ë£Œ!")